"""
Script para preparar el proyecto SAM LoRA para ser usado en Google Colab.
Crea un archivo ZIP optimizado y genera instrucciones de uso.
"""

import os
import sys
import zipfile
import shutil
from pathlib import Path
from datetime import datetime

# Agregar Core Modules al path
sys.path.insert(0, str(Path(__file__).parent.parent / "Core Modules"))


def create_colab_package(output_dir: str = None) -> str:
    """
    Crea un paquete ZIP del proyecto optimizado para Google Colab.
    
    Args:
        output_dir: Directorio donde guardar el ZIP. Si es None, usa el directorio padre.
    
    Returns:
        Ruta al archivo ZIP creado.
    """
    project_root = Path(__file__).parent.parent
    
    if output_dir is None:
        output_dir = project_root.parent
    else:
        output_dir = Path(output_dir)
    
    # Nombre del archivo ZIP con timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    zip_name = f"SAM_LoRA_Colab_{timestamp}.zip"
    zip_path = output_dir / zip_name
    
    print(f"üì¶ Creando paquete para Google Colab...")
    print(f"   Directorio del proyecto: {project_root}")
    print(f"   Archivo de salida: {zip_path}")
    
    # Archivos y carpetas a incluir
    include_items = [
        "Core Modules",
        "Main Scripts",
        "Utility Scripts",
        "Documentation",
        "requirements.txt",
        ".gitignore",
        "advanced_examples.py",
        "colab_setup.ipynb",
        "ESTRUCTURA_README.md"
    ]
    
    # Archivos a excluir (patterns)
    exclude_patterns = [
        "__pycache__",
        "*.pyc",
        "*.pyo",
        ".git",
        ".vscode",
        ".idea",
        "outputs",
        "checkpoints/*.pth",  # No incluir checkpoints grandes
        "*.pt",
        "*.pth",
        ".DS_Store",
        "*.log",
        "wandb",
        "optuna_study.db"
    ]
    
    def should_exclude(file_path: Path) -> bool:
        """Verifica si un archivo debe ser excluido."""
        path_str = str(file_path)
        for pattern in exclude_patterns:
            if pattern in path_str or file_path.name == pattern:
                return True
            if pattern.startswith("*.") and file_path.name.endswith(pattern[1:]):
                return True
        return False
    
    # Crear archivo ZIP
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for item in include_items:
            item_path = project_root / item
            
            if not item_path.exists():
                print(f"‚ö†Ô∏è  Omitiendo {item} (no existe)")
                continue
            
            if item_path.is_file():
                if not should_exclude(item_path):
                    arcname = f"SAM finetuning LoRA/{item}"
                    zipf.write(item_path, arcname)
                    print(f"   ‚úì {item}")
            
            elif item_path.is_dir():
                for root, dirs, files in os.walk(item_path):
                    # Filtrar directorios a excluir
                    dirs[:] = [d for d in dirs if not should_exclude(Path(root) / d)]
                    
                    for file in files:
                        file_path = Path(root) / file
                        
                        if not should_exclude(file_path):
                            # Mantener estructura de carpetas
                            rel_path = file_path.relative_to(project_root)
                            arcname = f"SAM finetuning LoRA/{rel_path}"
                            zipf.write(file_path, arcname)
                
                print(f"   ‚úì {item}/")
    
    # Obtener tama√±o del archivo
    size_mb = zip_path.stat().st_size / (1024 * 1024)
    print(f"\n‚úÖ Paquete creado exitosamente!")
    print(f"   Tama√±o: {size_mb:.2f} MB")
    print(f"   Ubicaci√≥n: {zip_path}")
    
    return str(zip_path)


def generate_colab_instructions(zip_path: str) -> None:
    """
    Genera instrucciones de uso para Google Colab.
    
    Args:
        zip_path: Ruta al archivo ZIP creado.
    """
    instructions = f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    INSTRUCCIONES PARA GOOGLE COLAB                          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üì¶ Archivo creado: {Path(zip_path).name}

üöÄ PASOS PARA USAR EN GOOGLE COLAB:

1Ô∏è‚É£  SUBIR A GOOGLE DRIVE:
    a) Abre Google Drive (drive.google.com)
    b) Crea una carpeta llamada "SAM_LoRA_Training"
    c) Sube el archivo {Path(zip_path).name} a esa carpeta

2Ô∏è‚É£  ABRIR NOTEBOOK EN COLAB:
    a) En Google Drive, haz doble clic en "colab_setup.ipynb" (dentro del ZIP)
    b) O ve a colab.research.google.com
    c) File ‚Üí Upload notebook ‚Üí Selecciona colab_setup.ipynb

3Ô∏è‚É£  CONFIGURAR GPU:
    Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU (T4)

4Ô∏è‚É£  EJECUTAR CELDAS DEL NOTEBOOK:
    Sigue las instrucciones en cada celda del notebook.
    El notebook te guiar√° paso a paso.

üìö ARCHIVOS IMPORTANTES:

    ‚Ä¢ colab_setup.ipynb                 ‚Üí Notebook principal para Colab
    ‚Ä¢ Documentation/GOOGLE_COLAB_GUIDE.md ‚Üí Gu√≠a detallada completa
    ‚Ä¢ ESTRUCTURA_README.md              ‚Üí Documentaci√≥n de la estructura
    ‚Ä¢ requirements.txt                  ‚Üí Dependencias de Python

‚ö° COMANDOS R√ÅPIDOS PARA COLAB:

    # Montar Google Drive
    from google.colab import drive
    drive.mount('/content/drive')
    
    # Descomprimir proyecto
    !unzip -q "/content/drive/MyDrive/SAM_LoRA_Training/{Path(zip_path).name}" -d /content/
    
    # Entrar al directorio
    %cd "/content/SAM finetuning LoRA"
    
    # Descargar checkpoint SAM
    !mkdir -p checkpoints
    !wget -O checkpoints/sam_vit_b_01ec64.pth \\
        https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth
    
    # Entrenar (ejemplo r√°pido)
    !python "Main Scripts/train.py" \\
        --checkpoint checkpoints/sam_vit_b_01ec64.pth \\
        --batch_size 2 --num_epochs 5

üîç TIPS:

    ‚úì Lee Documentation/GOOGLE_COLAB_GUIDE.md para gu√≠a completa
    ‚úì Usa el notebook colab_setup.ipynb para configuraci√≥n guiada
    ‚úì Guarda checkpoints en Drive para no perderlos
    ‚úì Usa --mixed_precision para ahorrar memoria GPU
    ‚úì Configura --save_frequency para checkpoints frecuentes

üí° SOLUCI√ìN DE PROBLEMAS:

    ‚Ä¢ "CUDA Out of Memory"     ‚Üí Reducir --batch_size a 1 o 2
    ‚Ä¢ "Runtime disconnected"   ‚Üí Usar script anti-desconexi√≥n (ver gu√≠a)
    ‚Ä¢ "Import error"           ‚Üí Verificar que est√©s en el directorio correcto
    ‚Ä¢ Dataset no encontrado    ‚Üí Usar rutas absolutas a /content/

üìñ M√ÅS INFORMACI√ìN:

    Documentaci√≥n completa: Documentation/GOOGLE_COLAB_GUIDE.md
    Estructura del proyecto: ESTRUCTURA_README.md
    README principal: Documentation/README.md

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  ¬°Ya est√°s listo para entrenar SAM con LoRA en Google Colab! üöÄ            ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""
    
    print(instructions)
    
    # Guardar instrucciones en archivo
    instructions_path = Path(zip_path).parent / "COLAB_INSTRUCTIONS.txt"
    with open(instructions_path, 'w', encoding='utf-8') as f:
        f.write(instructions)
    
    print(f"üìÑ Instrucciones guardadas en: {instructions_path}")


def check_dataset_size(dataset_path: str = None) -> None:
    """
    Verifica el tama√±o del dataset y da recomendaciones.
    
    Args:
        dataset_path: Ruta al dataset COCO. Si es None, usa la ruta por defecto.
    """
    if dataset_path is None:
        # Ruta por defecto relativa al proyecto
        project_root = Path(__file__).parent.parent
        dataset_path = project_root.parent / "Cataract COCO Segmentation" / "Cataract COCO Segmentation"
    
    dataset_path = Path(dataset_path)
    
    if not dataset_path.exists():
        print(f"‚ö†Ô∏è  Dataset no encontrado en: {dataset_path}")
        print("   Por favor especifica la ruta correcta con --dataset_path")
        return
    
    # Calcular tama√±o total
    total_size = 0
    file_count = 0
    
    for root, dirs, files in os.walk(dataset_path):
        for file in files:
            file_path = Path(root) / file
            total_size += file_path.stat().st_size
            file_count += 1
    
    size_mb = total_size / (1024 * 1024)
    size_gb = size_mb / 1024
    
    print(f"\nüìä INFORMACI√ìN DEL DATASET:")
    print(f"   Ubicaci√≥n: {dataset_path}")
    print(f"   Archivos: {file_count:,}")
    print(f"   Tama√±o total: {size_mb:.2f} MB ({size_gb:.2f} GB)")
    
    # Recomendaciones
    print(f"\nüí° RECOMENDACIONES PARA COLAB:")
    
    if size_gb < 1:
        print("   ‚úì Dataset peque√±o (<1GB)")
        print("   ‚Üí Puedes subirlo directamente a Colab")
        print("   ‚Üí O guardar en Google Drive")
    elif size_gb < 5:
        print("   ‚ö†Ô∏è  Dataset mediano (1-5GB)")
        print("   ‚Üí Mejor guardar en Google Drive")
        print("   ‚Üí Comprimir antes de subir (usa .zip)")
    else:
        print("   üî¥ Dataset grande (>5GB)")
        print("   ‚Üí DEBE estar en Google Drive")
        print("   ‚Üí Considerar comprimir o reducir tama√±o de im√°genes")
        print("   ‚Üí Alternativa: usar Roboflow para descarga directa en Colab")
    
    # Crear ZIP del dataset si es peque√±o
    if size_gb < 1:
        print(f"\n‚ùì ¬øCrear ZIP del dataset para Colab?")
        response = input("   (s/n): ").lower().strip()
        
        if response == 's':
            output_dir = dataset_path.parent
            zip_name = "cataract_dataset_colab.zip"
            zip_path = output_dir / zip_name
            
            print(f"\nüì¶ Comprimiendo dataset...")
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(dataset_path):
                    for file in files:
                        file_path = Path(root) / file
                        arcname = file_path.relative_to(dataset_path.parent)
                        zipf.write(file_path, arcname)
            
            zip_size_mb = zip_path.stat().st_size / (1024 * 1024)
            print(f"   ‚úÖ Dataset comprimido: {zip_path}")
            print(f"   Tama√±o: {zip_size_mb:.2f} MB")


def main():
    """Funci√≥n principal."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Prepara el proyecto SAM LoRA para Google Colab",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:
    
    # Crear paquete b√°sico
    python prepare_for_colab.py
    
    # Especificar directorio de salida
    python prepare_for_colab.py --output_dir "C:/Users/Usuario/Desktop"
    
    # Incluir an√°lisis del dataset
    python prepare_for_colab.py --check_dataset
    
    # Especificar ruta del dataset
    python prepare_for_colab.py --check_dataset --dataset_path "ruta/al/dataset"
        """
    )
    
    parser.add_argument(
        '--output_dir',
        type=str,
        default=None,
        help='Directorio donde guardar el ZIP (default: directorio padre del proyecto)'
    )
    
    parser.add_argument(
        '--check_dataset',
        action='store_true',
        help='Verificar tama√±o del dataset y dar recomendaciones'
    )
    
    parser.add_argument(
        '--dataset_path',
        type=str,
        default=None,
        help='Ruta al dataset COCO (default: ../Cataract COCO Segmentation/...)'
    )
    
    args = parser.parse_args()
    
    try:
        # Crear paquete ZIP
        zip_path = create_colab_package(args.output_dir)
        
        # Generar instrucciones
        generate_colab_instructions(zip_path)
        
        # Verificar dataset si se solicita
        if args.check_dataset:
            check_dataset_size(args.dataset_path)
        
        print("\n" + "="*80)
        print("‚úÖ PREPARACI√ìN COMPLETADA")
        print("="*80)
        print(f"\nüì¶ Sube estos archivos a Google Drive:")
        print(f"   1. {Path(zip_path).name}")
        if args.check_dataset:
            print(f"   2. cataract_dataset_colab.zip (si se cre√≥)")
        print(f"\nüìñ Lee COLAB_INSTRUCTIONS.txt para m√°s detalles")
        print(f"\nüöÄ Luego abre colab_setup.ipynb en Google Colab")
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
