# SAM LoRA Fine-tuning

## ğŸ“ Estructura del Proyecto

```text
SAM finetuning LoRA/
â”‚
â”œâ”€â”€ Core Modules/              # MÃ³dulos principales del framework
â”‚   â”œâ”€â”€ __init__.py           # InicializaciÃ³n del paquete
â”‚   â”œâ”€â”€ config.py             # ConfiguraciÃ³n del proyecto
â”‚   â”œâ”€â”€ dataset.py            # Carga y procesamiento de datos COCO
â”‚   â”œâ”€â”€ model.py              # Modelo SAM con LoRA
â”‚   â”œâ”€â”€ trainer.py            # LÃ³gica de entrenamiento
â”‚   â””â”€â”€ utils.py              # Utilidades (losses, mÃ©tricas, etc.)
â”‚
â”œâ”€â”€ Main Scripts/              # Scripts principales de ejecuciÃ³n
â”‚   â”œâ”€â”€ train.py              # Script de entrenamiento
â”‚   â”œâ”€â”€ inference.py          # Script de inferencia/testing
â”‚   â””â”€â”€ optuna_tuning.py      # OptimizaciÃ³n de hiperparÃ¡metros
â”‚
â”œâ”€â”€ Utility Scripts/           # Scripts auxiliares
â”‚   â”œâ”€â”€ quickstart.py         # Interfaz interactiva para comenzar
â”‚   â”œâ”€â”€ verify_setup.py       # VerificaciÃ³n de instalaciÃ³n
â”‚   â”œâ”€â”€ export_to_huggingface.py  # Exportar a HuggingFace Hub
â”‚   â”œâ”€â”€ prepare_for_colab.py  # Preparar paquete para Google Colab
â”‚   â””â”€â”€ run_training.ps1      # Script PowerShell con menÃº
â”‚
â”œâ”€â”€ SAM_LoRA_Fine_tuning_colab_setup.ipynb  # Notebook para Google Colab
â”œâ”€â”€ requirements.txt           # Dependencias de Python
â”œâ”€â”€ advanced_examples.py       # Ejemplos de uso avanzado
â””â”€â”€ .gitignore                # Archivos a ignorar en Git
```

## ğŸš€ CÃ³mo Usar 
### OpciÃ³n 1: Quick Start (Recomendado)

Desde cualquier ubicaciÃ³n dentro del proyecto:

```bash
# Desde la raÃ­z del proyecto
python "Utility Scripts/quickstart.py"

# O desde la carpeta Utility Scripts
cd "Utility Scripts"
python quickstart.py
```

### OpciÃ³n 2: Scripts Directos

```bash
# Entrenamiento
python "Main Scripts/train.py" --checkpoint checkpoints/sam_vit_b_01ec64.pth

# OptimizaciÃ³n con Optuna
python "Main Scripts/optuna_tuning.py" --checkpoint checkpoints/sam_vit_b_01ec64.pth --n_trials 50

# Inferencia
python "Main Scripts/inference.py" --checkpoint outputs/best_model.pt --split test
```

### OpciÃ³n 3: PowerShell Script (Windows)

```powershell
cd "Utility Scripts"
.\run_training.ps1
```

### OpciÃ³n 4: Google Colab

Para usar el proyecto en Google Colab:

```bash
# Usar directamente el notebook incluido
# Subir SAM_LoRA_Fine_tuning_colab_setup.ipynb a Google Colab
```


## ğŸ“ Notas Importantes

### 1. Imports AutomÃ¡ticos

Los scripts en `Main Scripts` y `Utility Scripts` automÃ¡ticamente agregan `Core Modules` al path de Python, por lo que no necesitas preocuparte por los imports.

### 2. Rutas Relativas

Todos los scripts usan rutas relativas correctas:

- Los scripts buscan archivos relativos al directorio raÃ­z del proyecto
- Los checkpoints se guardan en `outputs/` desde la raÃ­z
- Los datos se buscan en la ruta especificada en `--data_root`

### 3. VerificaciÃ³n del Setup

Antes de empezar, ejecuta:

```bash
python "Utility Scripts/verify_setup.py"
```

Este script verifica:

- âœ“ VersiÃ³n de Python
- âœ“ PyTorch y CUDA
- âœ“ Dependencias instaladas
- âœ“ Checkpoint de SAM
- âœ“ Datos COCO
- âœ“ Estructura de archivos
- âœ“ Imports de mÃ³dulos

## ğŸ”§ InstalaciÃ³n

### Windows (PowerShell)

```powershell
# 1. Crear entorno virtual
python -m venv venv

# 2. Activar entorno
.\venv\Scripts\Activate.ps1

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Crear carpeta para checkpoints
New-Item -ItemType Directory -Path "checkpoints" -Force

# 5. Descargar checkpoint de SAM
# OpciÃ³n A: Usar Invoke-WebRequest (PowerShell)
Invoke-WebRequest -Uri "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth" -OutFile "checkpoints/sam_vit_b_01ec64.pth"

# OpciÃ³n B: Descargar manualmente desde:
# https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth
# y guardar en: checkpoints/

# 6. Verificar instalaciÃ³n
python "Utility Scripts/verify_setup.py"
```

### Linux/macOS (Bash)

```bash
# 1. Crear entorno virtual
python -m venv venv

# 2. Activar entorno
source venv/bin/activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Descargar checkpoint de SAM
mkdir -p checkpoints
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth -O checkpoints/sam_vit_b_01ec64.pth

# 5. Verificar instalaciÃ³n
python "Utility Scripts/verify_setup.py"
```

## ğŸ“Š Ventajas de la Estructura del Proyecto

1. **OrganizaciÃ³n Clara**: SeparaciÃ³n lÃ³gica entre mÃ³dulos core, scripts principales y utilidades
2. **FÃ¡cil NavegaciÃ³n**: Estructura intuitiva tipo IDE/proyecto profesional
3. **Modularidad**: Core Modules puede ser importado como paquete independiente
4. **Escalabilidad**: FÃ¡cil agregar nuevos scripts o mÃ³dulos
5. **Mantenibilidad**: CÃ³digo relacionado agrupado lÃ³gicamente
6. **Profesional**: Estructura estÃ¡ndar de proyectos Python
7. **Multiplataforma**: Compatible con Windows, Linux y macOS
8. **Colab-Ready**: Incluye soporte completo para Google Colab

## ğŸ¯ Flujos de Trabajo Comunes

### Primera Vez

```bash
# 1. Verificar todo
python "Utility Scripts/verify_setup.py"

# 2. Empezar con quickstart
python "Utility Scripts/quickstart.py"
```

### Entrenamiento EstÃ¡ndar

**Bash/Linux/macOS:**
```bash
python "Main Scripts/train.py" \
    --checkpoint checkpoints/sam_vit_b_01ec64.pth \
    --batch_size 4 \
    --num_epochs 100
```

**PowerShell/Windows:**
```powershell
python "Main Scripts/train.py" `
    --checkpoint checkpoints/sam_vit_b_01ec64.pth `
    --batch_size 4 `
    --num_epochs 100
```

### OptimizaciÃ³n de HiperparÃ¡metros

**Bash/Linux/macOS:**
```bash
python "Main Scripts/optuna_tuning.py" \
    --checkpoint checkpoints/sam_vit_b_01ec64.pth \
    --n_trials 50
```

**PowerShell/Windows:**
```powershell
python "Main Scripts/optuna_tuning.py" `
    --checkpoint checkpoints/sam_vit_b_01ec64.pth `
    --n_trials 50
```

### Testing

**Bash/Linux/macOS:**
```bash
python "Main Scripts/inference.py" \
    --checkpoint outputs/sam_lora_cataract/checkpoints/best_model.pt \
    --split test \
    --save_visualizations
```

**PowerShell/Windows:**
```powershell
python "Main Scripts/inference.py" `
    --checkpoint outputs/sam_lora_cataract/checkpoints/best_model.pt `
    --split test `
    --save_visualizations
```

### Uso en Google Colab

**OpciÃ³n A: Preparar paquete localmente**

```bash
# Preparar paquete para Colab
python "Utility Scripts/prepare_for_colab.py"
# Esto genera un archivo ZIP que puedes subir a Colab
```

**OpciÃ³n B: Usar notebook directamente**

1. Subir `SAM_LoRA_Fine_tuning_colab_setup.ipynb` a Google Colab
2. Seguir las instrucciones en el notebook
3. El notebook incluye todo lo necesario para entrenar

## ğŸ“š Recursos Adicionales

Para mÃ¡s informaciÃ³n y casos de uso avanzados:

- `advanced_examples.py` - Ejemplos de uso avanzado del framework
- `SAM_LoRA_Fine_tuning_colab_setup.ipynb` - Notebook completo para Google Colab
- `Utility Scripts/prepare_for_colab.py` - Script para preparar paquete Colab
- DocumentaciÃ³n de cÃ³digo en cada mÃ³dulo con docstrings detallados

## âœ… Checklist de InstalaciÃ³n

Antes de comenzar a entrenar, verifica que todo estÃ© configurado:

- [ ] Entorno virtual creado y activado
- [ ] Dependencias instaladas (`pip install -r requirements.txt`)
- [ ] Checkpoint de SAM descargado en `checkpoints/sam_vit_b_01ec64.pth`
- [ ] Dataset COCO preparado y accesible
- [ ] `verify_setup.py` ejecutado exitosamente sin errores
- [ ] CUDA disponible (opcional, pero recomendado para entrenamiento)

## ğŸ“ Scripts Disponibles

### Scripts Principales (`Main Scripts/`)

- **`train.py`**: Script principal de entrenamiento con LoRA
- **`inference.py`**: EvaluaciÃ³n y testing del modelo entrenado
- **`optuna_tuning.py`**: OptimizaciÃ³n automÃ¡tica de hiperparÃ¡metros

### Scripts Utilitarios (`Utility Scripts/`)

- **`quickstart.py`**: Interfaz interactiva para comenzar rÃ¡pidamente
- **`verify_setup.py`**: VerificaciÃ³n completa del entorno
- **`export_to_huggingface.py`**: Exportar modelo a HuggingFace Hub
- **`prepare_for_colab.py`**: Preparar paquete optimizado para Google Colab
- **`run_training.ps1`**: Script PowerShell con menÃº interactivo (Windows)

## ğŸ› Troubleshooting

### Error: "No module named 'Core Modules'"

Los scripts automÃ¡ticamente agregan `Core Modules` al path. Si encuentras este error:

```python
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent / "Core Modules"))
```

### Error: CUDA out of memory

Reduce el `batch_size`:

```bash
# Linux/macOS/Windows
python "Main Scripts/train.py" --batch_size 2
```

### Error: Checkpoint no encontrado

AsegÃºrate de haber descargado el checkpoint SAM:

**PowerShell (Windows):**
```powershell
Invoke-WebRequest -Uri "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth" -OutFile "checkpoints/sam_vit_b_01ec64.pth"
```

**Bash (Linux/macOS):**
```bash
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth -O checkpoints/sam_vit_b_01ec64.pth
```

## ğŸ“„ Licencia

Este proyecto utiliza SAM (Segment Anything Model) de Meta AI.

Las contribuciones son bienvenidas. Por favor, abre un issue o pull request para mejoras o correcciones.

---

Â¡Ya estÃ¡s listo para usar el proyecto con su estructura organizada! ğŸš€
